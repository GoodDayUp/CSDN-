---
title: 史上最全！多图带你读懂各种常见卷积类型
---

[转] 原文链接：https://www.yanxishe.com/TextTranslation/1488

## 英文原文：

A Comprehensive Introduction to Different Types of Convolutions in Deep Learning




如果你在深度学习中听说过不同类型的卷积（例如2d/3d/1x1/转置卷积/空洞卷积（ATROUS）/深度可分离卷积/深度卷积/扁平卷积/分组卷积/随机分组卷积），并且对它们的实际含义感到困惑，那么本文就是为了让你理解它们是如何工作的。 

在本文中，我总结了在深度学习中常用的几种卷积类型，并尝试以一种人人都能理解的方式来解释它们。除了这篇文章之外，还有其他一些关于这个主题的好文章。请查阅它们（在参考文献中列出）。

希望本文能帮助您建立直觉，为您的研究提供有用的参考。请随时发表意见和建议。谢谢，尽情享受！） 

本文的内容包括：
1.卷积和互相关
2.深度学习中的卷积
3.3D卷积
4.1x1卷积
5、卷积算法
6、转置卷积（反卷积）
7.空洞卷积（带孔卷积）
8.可分离卷积
1. 扁平卷积
10.分组卷积
11. 混洗分组卷积
12.逐点分组卷积



## 1.卷积和互相关

卷积是一种广泛应用于信号处理、图像处理和其他工程/科学领域的技术。在深度学习中，一种模型结构：卷积神经网络（CNN）就是以这种技术命名的。然而，深度学习中的卷积本质上是信号/图像处理中的互相关。这两种操作之间有细微的区别。

在不深入细节的情况下，这里有不同之处。在信号/图像处理中，卷积定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162240652.png)
它被定义为两个函数的积的积分，其中一个函数在倒转和移位之后。下面的可视化演示了这个想法。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162252676.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

信号处理中的卷积。滤波器g反转，然后沿水平轴滑动。对于每个位置，我们计算F和反向G之间的交集面积。交集面积是特定位置的卷积值。图片来源于[此链接](http://fourier.eng.hmc.edu/e161/lectures/convolution/index.html)。

这里，函数g是滤波器。它是反向的，然后沿着水平轴滑动。对于每个位置，我们计算f和反向g之间的交叉区域。该交叉区域是该特定位置的卷积值。

另一方面，互相关又称滑动点积或滑动内积两个函数。互相关中的滤波器没有反转。它直接通过函数f滑动，F与G的交集区域为互相关。下面的图显示了相关性和交叉相关性之间的区别。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162350840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
信号处理中卷积和互相关的区别。图片来源于维基百科。

在深度学习中，卷积中的滤波器是不可逆的。严格地说，它是相互关联的。我们基本上执行元素乘法和加法。但是，在深度学习中称之为卷积是一种惯例。这很好，因为过滤器的权重是在训练过程中学会的。如果上面例子中的倒转函数g是正确的函数，那么在训练后，学习的滤波器看起来像倒转函数g。因此，在训练前不需要像真正的卷积那样先倒转滤波器。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162417993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)




## 2.深度学习中的卷积

卷积的目的是从输入中提取有用的特征。在图像处理中，卷积可以选择多种不同的滤波器。每种类型的过滤器都有助于从输入图像中提取不同的方面或特征，例如横向/纵向/对角线边缘。同样，在卷积神经网络中，通过卷积，利用训练过程中自动学习权值的滤波器来提取不同的特征。然后，所有这些提取的特征被“组合”以做出决定。

卷积有几个优点，如权值共享和平移不变性。卷积还考虑了像素的空间关系。这些任务可能非常有用，尤其是在许多计算机视觉任务中，因为这些任务通常涉及识别某些组件与其他组件在空间上有一定关系的对象（例如，狗的身体通常与头部、四条腿和尾巴相连）。

**2.1.卷积：单通道版本**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162447533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

单通道卷积。图像来源于[此链接](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)。

在深度学习中，卷积是元素的乘法和加法。对于具有1个通道的图像，卷积如下图所示。这里的过滤器是一个3 x 3矩阵，元素为[[0，1，2]，[2，2，0]，[0，1，2]]。滤波器在输入端滑动。在每一个位置上，它都进行元素乘法和加法。每个滑动位置以一个数字结束。最后的输出是一个3×3的矩阵。（注意，在本例中，步幅=1，填充=0。这些概念将在下面的算术部分中描述。
04

**2.2.卷积：多通道版本**

在许多应用程序中，我们处理的是具有多个通道的图像。一个典型的例子是RGB图像。每个RGB通道强调原始图像的不同方面，如下图所示。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162540634.png)


不同的渠道强调原始图像的不同方面。这张照片摄于中国云南省元阳市。

多通道数据的另一个例子是卷积神经网络中的层。卷积网络层通常由多个信道（通常是数百个信道）组成。每个通道描述前一层的不同方面。我们如何在不同深度的层之间进行转换？如何将深度为n的层转换为深度为m的层？

在描述这个过程之前，我们想澄清一些术语：层、通道、特征图、滤波器和核。从层次结构的角度来看，层和滤波器的概念处于同一层次，而通道和核则处于下面的一个层次。通道和特征图是一样的。一个图层可以有多个通道（或特征图）：如果输入是RGB图像，则输入图层有3个通道。“通道”通常用来描述“层”的结构。类似地，“核”用于描述“滤波器”的结构。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162554815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

“层”（“滤波器”）和“通道”（“核”）之间的区别。

滤波器和核之间的区别有点棘手。有时，它们可以互换使用，这会造成混乱。本质上，这两个术语有细微的区别。“核”是指一个二维权重数组。术语“滤波器”是指堆叠在一起的多个核的三维结构。对于二维滤波器，滤波和核是一样的。但是对于一个3D滤波器和深度学习中的大多数卷积来说，滤波器是核的集合。每个核都是唯一的，强调输入通道的不同方面。

有了这些概念，多通道卷积就如下所示。每个核被应用到前一层的输入通道上，以生成一个输出通道。这是一个核扩展的过程。我们对所有核重复这样的过程，以生成多个通道。然后将这些通道中的每一个相加，形成一个单独的输出通道。下图过程应该更清晰。


这里输入层是一个5 x 5 x 3矩阵，有3个通道。滤波器是一个3 x 3 x 3矩阵。首先，滤波器中的每个核分别应用于输入层中的三个通道。进行三次卷积，产生3个尺寸为3 x 3的通道。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162701711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

多通道二维卷积的第一步：滤波器中的每个核分别应用于输入层中的三个通道。图像来源于[此链接](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)。

然后将这三个通道相加（元素相加），形成一个单通道（3 x 3 x 1）。该通道是使用滤波器（3 x 3 x 3矩阵）对输入层（5 x 5 x 3矩阵）进行卷积的结果。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162737264.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

多通道二维卷积的第二步：然后将这三个通道相加（元素相加），形成一个单通道。图像来源于[此链接](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)。

同样，我们可以把这个过程看作是在输入层中滑动一个三维过滤矩阵。请注意，输入层和滤波器具有相同的深度（通道数=核数）。3D滤波器仅在图像的两个方向、高度和宽度上移动（这就是为什么这种操作称为二维卷积，尽管3D滤波器用于处理三维体积数据）。在每个滑动位置，我们执行元素相乘和相加，结果是一个数字。在下面的示例中，滑动在5个水平位置和5个垂直位置执行。总的来说，我们得到一个单一的输出通道。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162808796.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


另一种考虑二维卷积的方法是：把这个过程看作是在输入层中滑动一个三维过滤矩阵。请注意，输入层和滤波器具有相同的深度（通道数=核数）。3D滤波器仅在图像的两个方向、高度和宽度上移动（这就是为什么这种操作称为二维卷积，尽管3D滤波器用于处理三维体积数据）。输出是一个单层矩阵。

现在我们可以看到如何在不同深度的层之间进行过渡。假设输入层有Din通道，我们希望输出层有Dout通道。我们需要做的是将Dout滤波器应用到输入层。每个滤波器都有Din个核。每个滤波器提供一个输出通道。在应用了Dout滤波器之后，我们就有了Dout通道，这些通道可以叠加在一起形成输出层。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162820355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

标准二维卷积。使用Dout滤波器将一个具有深度Din的层映射到另一个具有深度Dout的层。


## 3.3D卷积

在上一节的最后一个插图中，我们看到我们实际上对一个3D执行卷积。但通常，我们仍然称这种操作为深度学习中的二维卷积。这是对三维体积数据的二维卷积。滤波深度与输入层深度相同。3D滤波器仅沿两个方向移动（图像的高度和宽度）。这种操作的输出是一个二维图像（只有一个通道）。

当然，还有三维卷积。它们是二维卷积的推广。在三维卷积中，滤波深度小于输入层深度（核大小<通道大小）。因此，3D滤波器可以在所有3个方向（图像的高度、宽度、通道）移动。在每个位置，元素的乘法和加法都提供一个数字。由于滤波器在三维空间中滑动，因此输出数字也排列在三维空间中。然后输出三维数据。
![在这里插入图片描述](https://img-blog.csdnimg.cn/2019092416285160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

在3D卷积中，3D滤波器可以在所有3个方向（图像的高度、宽度、通道）移动。在每个位置，元素的乘法和加法都提供一个数字。由于滤波器在三维空间中滑动，因此输出数字也排列在三维空间中。然后输出三维数据。

与二维卷积编码二维域中物体的空间关系类似，三维卷积可以描述三维空间中物体的空间关系。这种三维关系对于某些应用很重要，例如在生物医学成像的三维分割/重建中，如CT和MRI，其中血管等物体在三维空间中四处游荡。
07

## 4.1x1卷积

既然我们在前面的3d卷积部分讨论了深度操作，那么让我们来看另一个有趣的操作：1x1卷积。

你可能想知道为什么这是有帮助的。我们只是把一个数字乘以输入层中的每个数字吗？对于只有一个通道的层来说，操作很简单。在这里，我们将每个元素乘以一个数字。

如果输入层有多个通道，事情就会变得有趣。下图说明了1 x 1卷积如何用于尺寸为H x W x D的输入层。在1 x 1卷积（滤波器尺寸为1 x 1 x D）之后，输出通道的尺寸为H x W x 1。如果我们应用n个这样的1×1卷积，然后将结果连接在一起，我们就可以得到一个尺寸为h×w×n的输出层。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924162914838.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

1 x 1卷积，其中滤波器尺寸为1 x 1 x D。

最初，在[Network-in-network论文](http://xxx.itp.ac.cn/abs/1312.4400)中提出了1×1卷积。然后，他们在谷歌的[inception论文](http://xxx.itp.ac.cn/abs/1409.4842)中被广泛使用。1 x 1卷积的几个优点是：

   有效减少维度

   有效低维嵌入

   卷积后再应用非线性

上图中可以看到前两个优点。经过1×1的卷积，我们显著地减小了尺寸深度。假设原始输入有200个通道，那么1x1卷积将把这些通道（特性）嵌入到单个通道中。第三个优点是在1×1卷积之后，可以添加非线性激活，如relu。非线性允许网络学习更复杂的功能。

这些优势在Google的inception论文中描述为：

   “上述模块的一个大问题，至少在这种简单的形式下，就是即使是少量的5x5卷积，在具有大量滤波器的卷积层的顶部也会非常昂贵。

   这导致了所提议体系结构的第二个想法：明智地应用维度缩减和预测，否则计算需求会增加太多。这是基于嵌入的成功：即使是低维嵌入也可能包含大量关于相对较大的图像补丁的信息…也就是说，在昂贵的3 x 3和5 x 5卷积之前，使用1 x 1卷积来计算缩减。除了用作还原，它们还包括使用整流线性激活，这使它们具有双重用途。”

关于1×1卷积的一个有趣的观点来自于Yann Lecun：“在卷积网络中，没有所谓的“全连接层”。只有具有1x1卷积核和完整连接的卷积层。”
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163032951.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


## 5、卷积算法

我们现在知道如何处理卷积中的深度。让我们继续讨论如何处理其他两个方向（高度和宽度）的卷积，以及重要的卷积算法。

下面是一些术语：

卷积核大小：卷积核在前面的章节讨论过。卷积核大小决定了卷积的感受野大小。

步长：它定义了卷积核扫过特征图时的步长大小。步长为1表示卷积核逐个扫过特征图的像素。步长为2表示卷积核以每步移动2个像素（即跳过一个元素）扫描特征图。我们可以用步长（>=2）对特征图进行向下采样。

填充：它定义了如何处理特征图的边框。如果必要的话，在输入边界进行全0填充，填充卷积（Tersorflow中padding=‘same’）将保持输出和输入的特征图尺寸相同。另一方面，完全不使用填充的卷积（ Tersorflow中padding=‘valid’）只对输入的像素执行卷积，而不在输入边界填充0。输出的特征图尺寸小于输入的特征图尺寸。

下图展示了一个卷积核大小为3、步长为1和填充为1的二维卷积。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163102172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

有一篇讲解详细算法的优秀文章（“ [A guide to convolution arithmetic for deep learning](http://xxx.itp.ac.cn/abs/1603.07285) ”）关于卷积核大小、步长和填充的详细说明和示例，可以参考此文。在这里，我只是总结了一般情况下的结果。

对于尺寸为i、卷积核大小为k、填充为p、步长为s的输入图像，卷积后的输出图像尺寸o：


![在这里插入图片描述](https://img-blog.csdnimg.cn/2019092416321895.png)


## 6、转置卷积（反卷积）

对于许多应用程序和许多网络体系结构，我们通常希望能够对正常卷积在相反方向进行转换，即我们希望进行向上采样。一些例子包括生成高分辨率图像和将地位特征图映射到高维空间，如自动编码器或语义分割。（在后面的示例中，语义分割首先提取编码器中的特征图，然后在解码器中还原原始图像大小，以便对原始图像中的每个像素进行分类。）

习惯上，可以通过应用差值方案或手动创建规则来实现向上采样。神经网络等现代架构倾向于让网络本身在没有人为干预的情况下自动学习正确的转换。为了实现这一点，我们可以使用转置卷积。

在文献中, 转换卷积也被称为反卷积, 或小数步长卷积。但是, 值得注意的是, "反卷积" 这个名称不太合适，因为转换卷积并不是信号/图像处理中定义的真正的反卷积。从技术上讲，信号处理中的反卷积逆转了卷积操作。这里的情况并非如此。正因为如此，一些作者强烈反对将转置卷积称为反卷积。人们称之为反卷积主要是因为简单。稍后，我们将了解为什么将此类操作称为转置卷积是自然的，也是更合适的。
进行具有直接卷积的转置卷积是有可能的。对于下图中的一个示例, 我们在2 x 2的输入图像上应用单位步长、对边界进行 2 x 2 全0填充的 3 x 3 卷积核的转置卷积。向上采样输出图像的大小为 4 x 4。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163346681.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


向上采样 2 x 2 输入到 4 x 4 输出。图像是通过此链接采用的。

有趣的是，通过应用不同的填充和步长，可以将相同的 2 x 2 输入图像映射成不同大小的图像。接下来，我们在相同2 x 2的输入图像（在输入之间插入一个0）上应用单位步长、对边界进行 2 x 2 全0填充的转置卷积 。现在输出图像的大小为 5 x 5。






观察上面的例子中的转置卷积可以帮助我们建立一些直觉。但推广其应用，可以研究它在计算机中是如何通过矩阵乘法实现的。从那里，我们也可以明白为什么 "转置卷积" 才是一个合适的名称。

在卷积中，我们定义 C 作为我们的卷积核,  Large 作为输入图像, Small 作为卷积后的输出图像。卷积 (矩阵乘法) 后，我们将大图像向下采样为一个小的输出图像。矩阵乘法中卷积的实现遵循 C x Large = Small。

下面的示例演示此类操作的工作原理。它将输入扁平化为 16 x 1 矩阵，并将卷积核转换为稀疏矩阵 (4 x 16)。然后在稀疏矩阵和扁平输入之间应用矩阵乘法。之后,，生成的矩阵 (4 x 1) 将转换回 2 x 2 输出。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019092416374395.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


卷积的矩阵乘法: 从输入图像Large (4 x 4) 到输出图像Small (2 x 2)。

现在, 如果我们在方程的两侧乘以矩阵 CT  的转置，并使用矩阵的乘法及其转置矩阵给出一个单位矩阵的性质，那么我们有下面的公式 CT x Small = Large，如下图所示。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163800662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

卷积的矩阵乘法: 从输入图像 Small(2 x 2) 到输出图像Large (4 x 4)。

正如您在这里所看到的, 我们从一个小图像到一个大图像进行向上采样。这是我们想要实现的目标。现在,，你也可以理解 "转置卷积" 这个名字是从哪里来的。

转置卷积的一般算法可以在这篇优秀的文章(“深度学习的卷积算法指南”)中的关系13和关系14中找到。


**6.1.棋盘伪影**

人们在使用转置卷积时观察到的一个令人不满意的行为就是所谓的棋盘伪影。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163818471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
一些棋盘伪影的例子。图片来自[此文](https://distill.pub/2016/deconv-checkerboard/)。

文章"反卷积和棋盘伪影" 对此行为有很好的描述。请查看此文以了解更多详细信息。在这里，我只总结几个要点。

棋盘伪影是由转置卷积的 "不均匀重叠" 引起的。这种重叠在一些地方比其他地方会有更多的像棋盘一样的画。

在下图中，顶部层是输入层，底部层是转置卷积后的输出层。在转置卷积过程中，小尺寸的图层被映射到具有较大尺寸的图层中。

在示例 (a) 中，步长为 1，滤波器大小为2。如红色轮廓所示，输入上的第一个像素映射到输出上的第一个和第二个像素。如绿色轮廓所示，输入上的第二个像素映射到输出上的第二个像素和第三个像素。输出上的第二个像素接收来自输入上的第一个和第二个像素的信息。总体而言，输出中间部分的像素从输入中接收相同数量的信息。这里有一个卷积核重叠的区域。当滤波器大小在示例 (b) 中增加到3时，接收大多数信息的中心部分会缩小。但这可能不是一个大问题，因为重叠仍然是均匀的。输出中间部分中的像素从输入中接收相同数量的信息。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163855997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
图片来自此文 ([链接](https://distill.pub/2016/deconv-checkerboard/)) 并对图片进行了修改。


现在对于下面的示例，我们更改步长为2。在滤波器大小为2的例子(a)中，输出上的所有像素从输入接收相同数量的信息。它们都从输入的单个像素接收信息。这里没有转置卷积的重叠。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924163954478.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


图片来自此文 (链接) 并对图片进行了修改。

如果我们将示例(b)中的滤波器大小更改为4，则均匀重叠的区域将缩小。但是，仍然可以使用输出的中心部分作为有效输出，其中每个像素从输入接收相同数量的信息。

然而，如果我们将示例(c)和(d)中的滤波器大小更改为3和5，事情就变得有趣了。 对于这两种情况，输出上的每个像素接收的信息量与其相邻像素相比是不同的。 我们无法在输出中找到连续且均匀重叠的区域。

当滤波器的大小不能被步长整除时，转置卷积具有不均匀的重叠。这种不均匀的重叠在一些地方比其他地方放置了更多的颜料，因此产生了棋盘效应。事实上，不均匀重叠的区域在二维上往往更为极端。两种模式相乘，不均匀性变成平方。

在应用转置卷积时，可以做两件事来减少这种伪影。首先，确保你使用的滤波器大小可以被步长整除，避免重叠的问题。其次，我们可以使用步长为1的转置卷积，这有助于减少棋盘伪影。然而，正如在许多最近的模型中看到的那样，伪影仍然可以泄露出来。

此文进一步提出了一种更好的向上采样方法：先调整图像大小(使用最近邻插值或双线性插值)，然后再做一个卷积层。通过这样做，作者避免了棋盘效应。你可能希望在你的应用程序中尝试使用它。


## 7.空洞卷积（带孔卷积）

空洞卷积在这篇文章被介绍，后面文章中详细介绍了“基于空洞卷积的多尺度上下文聚合”

这是标准的离散卷积：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164021670.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164540281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

标准卷积

展开卷积如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164619327.png)

当L=1时，空洞卷积成为标准卷积。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164209808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

空洞卷积

直观地说，空洞卷积通过在内核元素之间插入空格来“膨胀”内核。这个额外的参数l（膨胀率）表示我们要扩大内核的范围。实现可能会有所不同，但通常在内核元素之间插入L-1空格。下图显示了当l=1、2和4时的内核大小。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019092416475941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
空洞卷积的接收域。我们基本上观察到一个大的接受域，而不增加额外的成本。

在图像中，3 x 3红点表示卷积后，输出图像为3 x 3像素。尽管三种空洞卷积都提供了相同尺寸的输出，但模型观察到的接收场却有很大的不同。L=1时，接收字段为3 x 3。L=2为7×7。当L=3时，接收文件增加到15 x 15。有趣的是，与这些操作相关的参数数量基本上是相同的。我们“观察”一个大的接收文件，不增加额外费用。因此，在不增加核大小的情况下，采用控端卷积来廉价地增加输出单元的接收场，这在多个控端卷积相继叠加时尤其有效。

本文的作者在“基于空洞卷积的多尺度上下文聚合”中构建了一个由多层空洞卷积构成的网络，其中每层的扩展速率L呈指数增长。因此，有效接收场呈指数增长，而参数数量仅随层线性增长！

本文采用空洞卷积的方法，在不丢失分辨率的情况下，系统地聚合多尺度上下文信息。本文表明，该模块提高了当时（2016年）最先进的语义分割系统的准确性。请查看这篇论文了解更多信息。
14

## 8.可分离卷积

可分离卷积用于一些神经网络架构，例如 MobileNet (Link)。可分离卷积分为空间可分离卷积（spatially separable convolution）和深度可分离卷积（depthwise separable convolution）。


**8.1 空间可分离卷积**

空间可分离卷积在图像的2维空间维度上执行，例如高和宽两个维度。从概念上来看，顾名思义，空间可分离卷积将卷积分解为两项单独的操作。下面例子中，一个卷积核为 3x3 的 Sobel 卷积核被拆分成了 3x1 和 1x3的两个卷积核。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164817822.png)

Sobel卷积核可以被裁分为3 x 1和1 x 3 kernel。


在卷积中，3x3 卷积核可以直接对图像进行卷积操作。在空间可分离卷积中，首先由 3x1 卷积核对图像进行卷积，之后再应用 1x3 卷积核。当执行相同的操作中，就值需要 6 个参数就够了，不用9个。

此外，比起卷积，空间可分离卷积要执行的矩阵乘法运算也更少。举一个具体的例子，用3x3卷积核在 5x5 图像上做卷积操作，要求横向扫描 3 个位置（以及纵向扫描 3 个位置）上的卷积核，共有 9 个位置，如下图标出的 9 个点所示。在每个位置都进行 9 次元素级别的乘法运算，共执行 9 x 9 = 81 次运算。


![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164837217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

标准卷积，在1通道上。

另一方面，对于空间可分离卷积，我们首先在5 x 5图像上用3 x 1卷积。这样的话就卷积核能横向扫描 5 个位置的以及纵向扫描 3 个位置，总共 5 x 3=15 个位置，如下图所标的点所示。这样的话就共要进行 15 x 3 = 45 次乘法运算。现在得到的是一个 3 x 5 的矩阵，这个矩阵经过 1 x 3 卷积核的卷积操作——从横向上的 3 个位置以及纵向上的 5 个位置来扫描该矩阵。对于这 9 个位置中的每一个，都进行了 3 次元素级别的乘法运算，这个步骤总共要求 9 x 3=27 次乘法运算。因此，总体上，该空间可分离卷积共进行了 45 + 27 = 72 次乘法运算，也比标准的卷积所要进行的乘法运算
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164847384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

可分离卷积，在一个通道上

让我们稍微概括一下上面的案例。假设我们现在设置 m x m 卷积核、卷积步长stride=1 、填充padding=0 ，对 N x N 图像做卷积操作。传统的卷积需要进行 (N-2) x (N-2) x m x m 次乘法运算，而空间可分离卷积只需要进行 N x (N-2) x m + (N-2) x (N-2) x m = (2N-2) x (N-2) x m 次乘法运算。空间可分离卷积与标准的卷积的计算成本之比为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924164858358.png)

对于图像大小为N大于过滤器大小（N >> m），这个比率就变成了 2 / m，这就意味着在这种渐进情况（N >> m）下，对于一个 3x3 的filter，空间可分离卷积与标准的卷积之间的计算成本比率为 2/3；对于一个 5x5 的过滤器，比率为 2/5；对于一个 7x7 的过滤器，比如为 2/7，以此类推。

虽然空间可分离卷积节省了计算成本，但是它很少应用于深度学习中。一个主要的原因是，并不是所有的卷积核都能被拆分为 2 个更小的卷积核。如果我们用这种空间可分离卷积来取代所有传统的卷积，就会束缚我们去搜寻训练期间所有可能存在的卷积核，因为这个训练的解可能是次优的。
16

**8.2 深度可分离卷积**

现在，让我们来了解下深度可分离卷积 depthwise separable convolutions，它在深度学习中的应用要更普遍得多（例如在 [MobileNet](http://xxx.itp.ac.cn/abs/1704.04861) 和 [Xception](http://xxx.itp.ac.cn/abs/1610.02357) 中）。深度可分离卷积由两步组成：depthwise卷积以及 1x1 卷积。

在介绍这些步骤前，值得回顾一下前面部分所提到的 2D 卷积和 1x1 卷积。让我们先快速过一下标准的 2D 卷积。举一个具体的案例，假设输入层的大小为 7 x 7 x 3（高 x 宽 x 通道），filter大小为 3 x 3 x 3，经过一个filter的 2D 卷积后，输出层的大小为 5 x 5 x 1（仅剩 1 个通道）。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165045553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
用1个标准的 2D 卷积filter创建一个 1 层的输出  

一般来说，两个神经网络层间应用了多个filter，现在假设filter个数为 128。128 次 2D 卷积得到了 128 个 5 x 5 x 1 的输出映射。然后将这些映射堆叠为一个大小为 5 x 5 x 128 的单个层。空间维度如高和宽缩小了，而深度则扩大了。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165055183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

用128个标准的 2D 卷积filter创建一个 128 层的输出

现在有了深度可分离的卷积，让我们看看我们如何实现相同的转换。

首先，我们在输入层上应用深度卷积。我们在 2D 卷积中分别使用 3 个卷积核（每个的大小为 3 x 3 x 1），而不使用一个 3 x 3 x 3大小的filter。每个卷积核仅对输入层的 1 个通道做卷积，这样的卷积每次都得出大小为 5 x 5 x 1 的映射，之后再将这些映射堆叠在一起创建一个 5 x 5 x 3 的图像，最终得出一个大小为 5 x 5 x 3 的输出图像。这样的话，图像的空间维度缩小了，但是深度保持与原来的一样。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165105982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

深度可分离卷积过程—第一步：在 2D 卷积中分别使用 3 个卷积核（每个的大小为 3 x 3 x 1），而不使用大小为 3 x 3 x 3 的单个过滤器。每个卷积核仅对输入层的 1 个通道做卷积，这样的卷积每次都得出大小为 5 x 5 x 1 的映射，之后再将这些映射堆叠在一起创建一个 5 x 5 x 3 的图像，最终得出一个大小为 5 x 5 x 3 的输出图像。



深度可分离卷积的第二步是扩大深度，我们用大小为 1x1x3 的卷积核做 1x1 卷积操作。每个 1x1x3 卷积核对 5 x 5 x 3 输入图像做卷积后都得出一个大小为 5 x 5 x1 的映射。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165216926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
这样，做 128 次 1x1 卷积后，就可以得出一个大小为 5 x 5 x 128 的层

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165230618.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

深度可分离卷积完成这两步后，同样可以将一个 7 x 7 x 3 的输入层转换为 5 x 5 x 128 的输出层。

深度可分离卷积的完整过程如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165242913.png)

深度可分离卷积的完整过程


因此，做深度可分离卷积的优势是什么？高效！相比于 2D 卷积，深度可分离卷积的执行次数要少得多。

让我们回忆一下 2D 卷积案例中的计算成本：128 个 3x3x3 的卷积核移动 5x5 次，总共需要进行的乘法运算总数为 128 x 3 x 3 x 3 x 5 x 5 = 86,400 次。

那可分离卷积呢？在深度卷积这一步，有 3 个 3x3x3 的卷积核移动 5x5 次，总共需要进行的乘法运算次数为 3x3x3x1x5x5 = 675 次；在第二步的 1x1 卷积中，有 128 个 3x3x3 的卷积核移动 5x5 次，总共需要进行的乘法运算次数为 128 x 1 x 1 x 3 x 5 x 5 = 9,600 次。因此，深度可分离卷积共需要进行的乘法运算总数为 675 + 9600 = 10,275 次，花费的计算成本仅为 2D 卷积的 12%。




因此对于任意大小的图像来说，应用深度可分离卷积能节省多少次计算呢？我们稍微概括一下上面的案例。假设输入图像大小为 H x W x D，2D 卷积的卷积步长为 1，填充为 0，卷积核大小为 h x h x D（两个 h 相等）、个数为 Nc。2D 卷积后，大小为 (H x W x D) 的输入层最终转换为大小为(H-h+1 x W-h+1 x Nc) 的输出层，总共需要进行的乘法运算次数为：

Nc x h x h x D x (H-h+1) x (W-h+1)

针对同样的转换，深度可分离卷积总共需要进行的乘法运算次数为：

D x h x h x 1 x (H-h+1) x (W-h+1) + Nc x 1 x 1 x D x (H-h+1) x (W-h+1) = (h x h + Nc) x D x (H-h+1) x (W-h+1)

深度可分离卷积与 2D 卷积之间的乘法运算次数之比为：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165302116.png)
对于大部分现代框架而言，输出层往往都有许多个通道，例如几百甚至几千个通道。对于 Nc >> h 的层，上面的表达式会缩短为 1/h/h，这就意味着对于这个表达式而言，如果使用的 3 x 3大小的filter，这样2D卷积需要进行的乘法运算次数比深度可分离卷积多出 9 次；使用大小为 5 x5 的过滤器，则要多出 25 次。

使用深度可分离卷积有什么缺点吗？当然有。深度可分离卷积减少了卷积中的参数数量。因此，在小型模型中，如果用深度可分离卷积替换2D卷积，则模型容量可以显着降低。结果，该模型可能变得次优。但是，如果使用得当，深度可分离卷积可以提高效率而不会明显损害模型的性能。


## 9. 扁平卷积

在文章“[Flattened convolutional neural networks for feedforward acceleration](http://xxx.itp.ac.cn/abs/1412.5474)”中介绍了扁平卷积 flattened convolution。直观上，这种卷积的就是用filter分离的思想，即将标准的filter 拆分为 3 个1D filter，而不是直接应用一个标准的卷积filter来将输入层映射为输出层。这个思路类似于前部分所提到的空间可分离卷积，其中的一个2D的空间filter近似于两个rank-1 1D的。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165333606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

图片源自 论文 

需要注意到一点，如果标准卷积的filter是rank-1 filter，这样的filter可以被拆分为 3 个 1D 过滤器的交叉乘积，但是这是一个前提条件并且标准filter的固有 rank 往往比现实应用中的更高。正如论文中所指出的：「随着分类问题的难度增加，解决该问题还需要更多的关键部分... 深度网络中学习过滤器具有分布的特征值，并且将分离直接用于过滤器会导致明显的信息丢失。」

为了减轻这类问题，论文限制了感受野的关系从而让模型可以根据训练学习 1D 分离的过滤器。这篇论文声称，通过使用由连续的 1D 过滤器组成的扁平化网络在 3D 空间的所有方向上训练模型，能够提供的性能与标准卷积网络相当，不过由于学习参数的显著减少，其计算成本要更低得多。
20

## 10. 分组卷积


在2012年，AlexNet（链接）论文最先提出分组卷积的概念。



实现它的主要原因是——要使用两个内存有限的GPU（每个GPU 1.5GB内存）进行网络培训。下面的Alexnet在大多数层显示了两个独立的卷积路径。它在两个GPU之间执行模型并行化（当然，如果有更多的GPU可用，可以执行多个GPU并行化）。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165410337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
  在AlexNet（链接）论文中使用的图片


接下来，我们即将描述分组卷积的工作原理。首先，传统的二维卷积遵循以下步骤。在本例中，通过应用128个过滤器（每个过滤器的大小为3 x 3 x 3），将大小为（7 x 7 x 3）的输入层转换为大小为（5 x 5 x 128）的输出层。或者，在一般情况下，通过使用Dout内核(每一个都是 size h x w x Din).，size的输入层 (Hin x Win x Din) 会转换成size的输出层 (Hout x Wout x Dout) 。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165513950.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
  标准二维卷积

在分组卷积中，滤波器被分成不同的组。每组负责具有一定深度的传统二维卷积。下面的例子可以更清楚地说明这一点。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165622303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
  分组卷积与2个滤波器组。




上面是两个滤波器组分组卷积的图示。在每个滤波器组中，每个滤波器的深度仅为名义二维卷积的一半。深度为DIN/2。每个过滤器组包含DOUT/2过滤器。第一滤波器组（红色）与输入层的前半部分（[：，：，0:din/2]）卷积，而第二滤波器组（蓝色）与输入层的后半部分（[：，：，din/2:din]）卷积。因此，每个过滤器组创建DOUT/2通道。总的来说，两个组创建2个dout/2=dout通道。然后我们将这些通道与dout通道叠加在输出层中。
21

**10.1 分组卷积 VS 深度卷积**

你可能已经观察到了分组卷积和深度可分离卷积中用到的深度卷积之间的某些联系和区别。如果过滤器组的数量与输入层的通道数相同，每个过滤器的深度就是 Din / Din = 1，其与深度卷积中的过滤器深度相同。

从另一个角度来说，每个过滤器组现在包含 Dout / Din 个过滤器。总体而言，其输出层的深度就是 Dout，这就与深度卷积的输出层深度不同，深度卷积不改变层的深度，但随后深度可分离卷积中的 1 x 1 卷积会加大层的深度。

执行分组卷积有如下几个优势：

**第一个优势是训练的高效性。**由于卷积被拆分到几条路线中，每条路线都由不同的 GPU 分别进行处理。这一过程就允许模型以平行的方式在多个 GPU 上进行训练。比起在一个 GPU 上一个一个地训练模型，这种在多个 GPU 上的模型并行化训练方式每一步都可以给网络喂养更多的图像。模型并行化被认为比数据并行化更佳，后者将数据集进行拆分，然后对每一批数据进行训练。不过，当每批数据的大小过小时，我们执行的工作基本上是随机的，而不是批量梯度下降。这就会造成训练速度变慢或聚合效果变差的结果。

对于训练非常深度的神经网络，分组卷积变得很重要，如下图中 ResNeXt 所示

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165635576.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
图片源自：https://arxiv.org/abs/1611.05431

**第二个优势是模型更加高效，**例如，当过滤器组数增加时，模型参数就会减少。在前一个案例中，在标准的 2D 卷积中，过滤器有 h x w x Din x Dout 个参数，而在拆分为 2 个过滤器组的分组卷积中，过滤器仅有 (h x w x Din/2 x Dout/2) x 2 个参数：参数数量减少了一半。
22

**第三个优势是给人带来了些惊喜的。**分组卷积能提供比标准 2D 卷积更好的模型。另一篇很棒的博客

「A Tutorial on Filter Groups (Grouped Convolution)」阐述了这一点。这里仅提取了文章的部分内容，大家可前往 https://blog.yani.io/filter-group-tutorial/ 阅读全文。

其原因与稀疏的过滤器有关。下面的图像就是相邻层的过滤器之间的相互关系，这个关系是稀疏的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165731209.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


在 CIFAR10 训练的 Network-in-Network 模型中相邻层的过滤器之间的相关性矩阵。高相关的过滤器对更亮，而低相关过滤器对更暗。图片源自：https://blog.yani.io/filter-group-tutorial/

那针对分组卷积的相关性映射是怎么样的呢？

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924170456660.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

当采用 1、2、4、8 和 16 个过滤器组训练时，在 CIFAR10 训练的 Network-in-Network 模型中相邻层的过滤器之间的相关性。图片源自：https://blog.yani.io/filter-group-tutorial/

上图表示的就是模型采用 1、2、4、8 和 16 个过滤器组训练时，相邻层的过滤器的相互关系。这篇文章提出了一个推论：「过滤器组的作用就是学习通道维度上的块对角结构的稀疏性... 在对过滤器进行了分组的网络中，高相关性的过滤器以更结构化的方式学习。结果，不要求学习的过滤器关系也不再需要用参数进行表示，这就显著减少了网络中的参数数量，并且在减少参数的过程中不容易过度拟合，因此这种类似正则化的效果可以让优化器学习更准确、更有效的深度网络。」
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165941272.png)

过滤器分离：正如论文作者所指出的，过滤器组似乎将学习的过滤器分为两个不同的组：黑白过滤器和彩色过滤器。图片源自：https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf

此外，每个过滤器组都学习数据独一无二的表示。正如 AlexaNet 这篇论文的作者所提到的，过滤器组似乎将学习的过滤器组织成了两个不同的组：黑白滤镜和彩色滤镜。

## 11. 混洗分组卷积

旷视研究院(Face++) ShuffleNet论文中介绍了混洗分组卷积（Shuffled grouped convolution）. ShuffleNet 是一种高效率计算的卷积架构，专为计算能力非常有限（例如10-150 MFLOPs）的移动设备而设计。

混洗分组卷积背后的思路与分组卷积（用于  MobileNet 、ResNeXt 等网络）以及深度可分离卷积（用于Xception）背后的思路相关。  

总的来说，混洗分组卷积包括分组卷积和通道混洗（channel shuffling）。

在分组卷积部分，我们了解了卷积核filters被拆分为不同的组，每个组都拥有一定深度的 2D卷积的负责一定深度的特征提取的工作，这样显著减少了整个操作的步骤。在下图这个案例中，假设filters 分成了 3 组。第一个 filter 组对输入层的红色部分做卷积；第二个和第三个 filter 组分别对输入层的绿色和蓝色部分做卷积。每个过滤器组中的卷积核深度仅为输入层整个通道的 1/3。在这个案例中，进行第一个分组卷积 GConv1 后，输入层被映射到中间的特征图上，之后通过第二组分卷积GConv2将该特征图映射到输出层。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924165953697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

分组卷积计算效率高。但存在的问题是每个filter组仅对从前面层的固定部分向后传递的信息进行处理。对于上图中的示例，第一个 filter 组（红色）仅处理从前1/3输入通道传递的信息。蓝色 filter 组仅处理从最后1/3的输入通道传递下来的信息。因此，每个 filter 组仅限于学习一些特定特征。这种属性就阻碍了训练期间信息在通道组之间流动，并且还削弱了特征表示。为了克服这一问题，我们可以用通道混洗(channel shuffle)。

通道混洗的思路就是混合来自不同filter组的信息。下图中，显示了应用有 3 个filter组的第一个分组卷积 GConv1 后所得到的特征图map。在将这些特征maps输入到第二个分组卷积之前，先将每个组中的通道拆分为几个小组，然后再混合这些小组。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924170003306.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

Channel shuffle.

经过这种混洗分组后，我们再接着执行第二个分组卷积 GConv2。但是现在，由于混洗层中的信息已经混合，我们实质上是为GConv2中的每个组提供了特征映射层（或输入层）中的不同组。因此，不仅信息可以在通道组间进行流动，特征表示也得到增强。




## 12.逐点分组卷积

ShuffleNet这篇论文（link）还介绍了逐点分组卷积。通常，对于组卷积，例如在MobileNet（link）或ResNeXt（link）文章中提到，组操作是3x3的空间卷积执行的，而不是1 x 1卷积上执行。

shuffleNet论文认为，1 x 1卷积的计算成本也很高。它建议将组卷积用1 x 1大小的卷积。正如名称所示，逐点分组卷积执行1 x 1卷积的组操作。该操作与分组卷积相同，只有一个修改 - 是在1x1而不是NxN(N>1)大小的filter上执行。

在ShuffleNet论文中，作者使用了我们学到的三种类型的卷积：（1）混洗分组卷积; （2）逐点分组卷积; （3）深度可分离卷积。这种架构设计显着降低了计算成本，同时保持了准确性。例如，ShuffleNet可以在实际移动设备上达到和与AlexNet的较接近的分类误差。同时，计算成本已经从AlexNet的720 MFLOPs 大幅降低到ShuffleNet的 40-140 MFLOP。由于计算成本相对较小且模型性能良好，ShuffleNet在移动设备的卷积神经网络领域获得了普及。

感谢您阅读本文。请随时在下面留下问题和评论。

## 参考文献

博文 & 网文

   “An Introduction to different Types of Convolutions in Deep Learning” (Link)

   “Review: DilatedNet — Dilated Convolution (Semantic Segmentation)” (Link)

   “ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices” (Link)

   “Separable convolutions “A Basic Introduction to Separable Convolutions” (Link)

   Inception network “A Simple Guide to the Versions of the Inception Network” (Link)

   “A Tutorial on Filter Groups (Grouped Convolution)” (Link)

   “Convolution arithmetic animation” (Link)

   “Up-sampling with Transposed Convolution” (Link)

   “Intuitively Understanding Convolutions for Deep Learning” (Link)

论文

   Network in Network (Link)

   Multi-Scale Context Aggregation by Dilated Convolutions (Link)

   Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs (Link)

   ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices (Link)

   A guide to convolution arithmetic for deep learning (Link)

   Going deeper with convolutions (Link)

   Rethinking the Inception Architecture for Computer Vision (Link)

   Flattened convolutional neural networks for feedforward acceleration (Link)

   Xception: Deep Learning with Depthwise Separable Convolutions (Link)

   MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (Link)

   Deconvolution and Checkerboard Artifacts (Link)

   ResNeXt: Aggregated Residual Transformations for Deep Neural Networks (Link)

